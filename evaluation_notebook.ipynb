{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2c1411-1ef2-410f-8d11-c6c7e47c1f63",
   "metadata": {},
   "source": [
    "# Gene-Taxa Downstream Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fb3aef-b37b-4689-b372-0e522ec92005",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c74eed22-5465-49b2-9489-3178fe52d426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-17 15:21:35--  https://zenodo.org/api/records/12964684/files-archive\n",
      "Resolving zenodo.org (zenodo.org)... 188.184.103.159, 188.185.79.172, 188.184.98.238, ...\n",
      "Connecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘gene-taxa-dataset/files-archive’\n",
      "\n",
      "files-archive           [    <=>             ] 945.97M  18.2MB/s    in 73s     \n",
      "\n",
      "2024-10-17 15:22:49 (13.0 MB/s) - ‘gene-taxa-dataset/files-archive’ saved [991921356]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P gene-taxa-dataset https://zenodo.org/api/records/12964684/files-archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b38bf49-a5cf-4578-9b96-9e7309df484a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  gene-taxa-dataset/files-archive\n",
      " extracting: gene-taxa-dataset/val.fasta  \n",
      " extracting: gene-taxa-dataset/hierarchical-level.txt  \n",
      " extracting: gene-taxa-dataset/test.fasta  \n",
      " extracting: gene-taxa-dataset/gene_out.fasta  \n",
      " extracting: gene-taxa-dataset/taxa_out.fasta  \n",
      " extracting: gene-taxa-dataset/train.fasta  \n",
      " extracting: gene-taxa-dataset/metadata.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip gene-taxa-dataset/files-archive -d gene-taxa-dataset\n",
    "!rm gene-taxa-dataset/files-archive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf52f2-de35-46d2-85de-96c668418e22",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Kraken2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5a471-3a18-4e46-8e4a-9856b39a2d40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Rename the Header of FASTA File for Compatibility with Kraken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49705971-ee11-4415-a20d-069b25601104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Directory containing the FASTA files\n",
    "fasta_dir = \"gene-taxa-dataset\"\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(fasta_dir):\n",
    "    if file_name.endswith(\".fasta\"):  # Check if it's a FASTA file\n",
    "        input_file = os.path.join(fasta_dir, file_name)\n",
    "        output_file = os.path.join(fasta_dir, f\"{file_name.split('.')[0]}_kraken_like.fasta\")\n",
    "        \n",
    "        # Open the output file\n",
    "        with open(output_file, \"w\") as outfile:\n",
    "            # Process each sequence in the FASTA file\n",
    "            with open(input_file, \"r\") as infile:\n",
    "                for record in SeqIO.parse(infile, \"fasta\"):\n",
    "                    # Split the header and rearrange the parts\n",
    "                    parts = record.id.split('|')\n",
    "                    new_header = f\">{parts[3]}|{parts[0]}|{parts[1]}|kraken:taxid|{parts[3]}\"\n",
    "                    \n",
    "                    # Write the modified header and sequence to the output file\n",
    "                    outfile.write(f\"{new_header}\\n{record.seq}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f696895-39e0-4a21-94b7-563f2e6fc0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45a1a0b8-f823-4b70-a2d8-d7bce8407e95",
   "metadata": {},
   "source": [
    "##### It is required to download the latest version of Kraken2. The version we used is from 23 November 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81905c8-4252-4c17-9da6-815dd27769a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d88fa6c-54a1-43d4-88c4-96e5b2f3e05f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Download Taxanomy db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6143e1d4-d678-4b20-9455-993eb241a80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:   \u001b[0m User not listed in /etc/subuid, trying root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m Using fakeroot command combined with root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /etc/localtime required more than 50 (79) bind mounts\n",
      "Downloading nucleotide gb accession to taxon map..."
     ]
    }
   ],
   "source": [
    "!singularity exec --fakeroot --bind {os.getcwd()}:/data kraken2_latest.sif kraken2-build --download-taxonomy --db /data/data-gene/databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8229e-cec4-48e2-9fb6-ddbe7bf89a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8fda0d-a38e-4aa9-976a-baa6ba3874c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd4c21f-fb13-41ea-b027-e6d1d6cb22bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create db from train.fasta file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c49b94c4-4438-407b-acbc-33f1205d89bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:   \u001b[0m User not listed in /etc/subuid, trying root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m Using fakeroot command combined with root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /etc/localtime required more than 50 (79) bind mounts\n",
      "Masking low-complexity regions of new file... done.\n",
      "Added \"/data/gene-taxa-dataset/train_kraken_like.fasta\" to library (/data/data-gene/databases)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!singularity exec --fakeroot --bind {os.getcwd()}:/data kraken2_latest.sif kraken2-build --add-to-library /data/gene-taxa-dataset/train_kraken_like.fasta --db /data/data-gene/databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc1b14-7cb3-4341-bc1c-a0cfc05de17f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Infrence on taxa_out for Kraken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c6ae5a8-8bb7-4b74-b160-5f17d7c10e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘taxa_out_output’: File exists\n",
      "\u001b[34mINFO:   \u001b[0m User not listed in /etc/subuid, trying root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m Using fakeroot command combined with root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /etc/localtime required more than 50 (79) bind mounts\n",
      "Loading database information... done.\n",
      "11800 sequences (12.38 Mbp) processed in 1.202s (589.0 Kseq/m, 617.98 Mbp/m).\n",
      "  5896 sequences classified (49.97%)\n",
      "  5904 sequences unclassified (50.03%)\n"
     ]
    }
   ],
   "source": [
    "! mkdir taxa_out_output\n",
    "!singularity exec --fakeroot --bind {os.getcwd()}:/data kraken2_latest.sif \\\n",
    "kraken2 --db /data/data-gene/databases \\\n",
    "--output /data/taxa_out_output/kraken2_results.txt \\\n",
    "--report /data/taxa_out_output/kraken2_report.txt \\\n",
    "--minimum-hit-groups 1 \\\n",
    "--confidence 0 \\\n",
    "/data/gene-taxa-dataset/taxa_out_kraken_like.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5424f72-4e44-4cbd-a5a6-b918de3094cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def traverse_nodes(initial_taxid, nodes_dict):\n",
    "    taxids = [initial_taxid]\n",
    "    ranks = []\n",
    "    wanted_ranks = np.array(['superkingdom','kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species'])\n",
    "    \n",
    "    while initial_taxid in nodes_dict.keys():\n",
    "        taxid, rank = nodes_dict[initial_taxid]\n",
    "        taxids.append(taxid)\n",
    "        ranks.append(rank)\n",
    "        initial_taxid = taxid\n",
    "        if initial_taxid == 1:\n",
    "            break\n",
    "    ranks = np.array(ranks)\n",
    "    mask = np.nonzero(np.in1d(ranks, wanted_ranks))[0]\n",
    "        \n",
    "    taxids = list(np.array(taxids)[mask])\n",
    "    ranks = list(np.array(ranks)[mask])\n",
    "    zipped_taxids = dict(zip(ranks, taxids))\n",
    "\n",
    "    return zipped_taxids\n",
    "\n",
    "#tree file\n",
    "nodes = pd.read_csv('./data-gene/databases/taxonomy/nodes.dmp', delimiter = \"\\t\", header=None, skipinitialspace=True, usecols=[0,2,4])\n",
    "nodes.rename(columns={0: 'taxid', 2: 'prev_taxid', 4: 'rank'}, inplace=True)\n",
    "\n",
    "#taxid -> name file\n",
    "names = pd.read_csv('./data-gene/databases/taxonomy/names.dmp', delimiter = \"\\t\", header=None, skipinitialspace=True, usecols=[0,2])\n",
    "names.rename(columns={0: 'taxid', 2: 'name'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc2bbfd-2141-4996-b0e7-9d74e8c7c637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f88cc32-e490-4df3-9a14-bbac715eff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#List of taxids\n",
    "basic = pd.read_csv('./taxa_out_output/kraken2_results.txt', delimiter = \"\\t\", header=None, skipinitialspace=True) # usecols=[0,2])\n",
    "\n",
    "basic[\"orginal_index\"] = basic[1].str.extract(r'seqid\\|(\\d+)', expand=False).astype(int)\n",
    "basic[\"taxid\"] = basic[1].str.extract(r'(\\d+)|', expand=False).astype(int)\n",
    "\n",
    "basic.rename(columns={2: 'pred_taxid'}, inplace=True)\n",
    "\n",
    "#traverse tree\n",
    "values = list(zip(nodes['prev_taxid'], nodes['rank']))\n",
    "keys = list(nodes['taxid'])\n",
    "nodes_dict = dict(map(lambda i,j : (i,j) , keys,values))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5e45f90-6305-4894-b48a-413d379c8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_taxa = basic.copy()\n",
    "full_taxa['real_taxa'] = full_taxa.apply(lambda row: traverse_nodes(row['taxid'], nodes_dict), axis=1)\n",
    "                                                  \n",
    "lineage = pd.DataFrame(list(full_taxa['real_taxa'])).fillna(0).astype('Int64') # lineage from taxid  \n",
    "\n",
    "full_taxa = basic.copy()\n",
    "full_taxa['real_taxa'] = full_taxa.apply(lambda row: traverse_nodes(row['pred_taxid'], nodes_dict), axis=1)\n",
    "lineage_pred = pd.DataFrame(list(full_taxa['real_taxa'])).fillna(0).astype('Int64') # lineage from taxid   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b4ff22-0b4d-40b1-a669-e7bdae5ed06c",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78a62fa-b827-44d4-8529-ce7459a2ed69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e25a7bc-05c3-49be-b849-bad14332a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialize accuracy dictionary to store accuracy for each level\n",
    "accuracy = {}\n",
    "\n",
    "# Loop through each level\n",
    "for level in lineage.columns:\n",
    "    # Check if the level exists in both DataFrames\n",
    "    if level in lineage_pred.columns:\n",
    "        # Count the number of matching values at this level, while ignoring rows where lineage_pred value is zero\n",
    "        matches = ((lineage[level] == lineage_pred[level]) & (lineage_pred[level] != 0)).sum()\n",
    "        # Count the total number of non-zero values in lineage_pred at this level\n",
    "        total_values = len(lineage)\n",
    "        # Calculate accuracy\n",
    "        if total_values != 0:\n",
    "            level_accuracy = matches / total_values\n",
    "        else:\n",
    "            level_accuracy = None\n",
    "        # Store accuracy for this level\n",
    "        accuracy[level] = level_accuracy\n",
    "\n",
    "# Print accuracy for each level\n",
    "for level, acc in accuracy.items():\n",
    "    print(f\"Accuracy for level {level}: {acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637b133-14f4-4f7d-adbf-32745f44fb10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27079cac-76d4-451e-8bf6-a47d3a446bdb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Mmseq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba691bb-337e-42e8-b738-fdc0bb453c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f5fc338-34b6-4de2-8002-d4cc39972b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create directory tmp\n",
      "easy-search gene-taxa-dataset/taxa_out.fasta gene-taxa-dataset/train.fasta ./taxa_out.m8 tmp --max-accept 1 --max-seqs 1 --search-type 3 \n",
      "\n",
      "MMseqs Version:                        \tf6c98807d589091c625db68da258d587795acbab\n",
      "Substitution matrix                    \taa:blosum62.out,nucl:nucleotide.out\n",
      "Add backtrace                          \tfalse\n",
      "Alignment mode                         \t3\n",
      "Alignment mode                         \t0\n",
      "Allow wrapped scoring                  \tfalse\n",
      "E-value threshold                      \t0.001\n",
      "Seq. id. threshold                     \t0\n",
      "Min alignment length                   \t0\n",
      "Seq. id. mode                          \t0\n",
      "Alternative alignments                 \t0\n",
      "Coverage threshold                     \t0\n",
      "Coverage mode                          \t0\n",
      "Max sequence length                    \t65535\n",
      "Compositional bias                     \t1\n",
      "Compositional bias                     \t1\n",
      "Max reject                             \t2147483647\n",
      "Max accept                             \t1\n",
      "Include identical seq. id.             \tfalse\n",
      "Preload mode                           \t0\n",
      "Pseudo count a                         \tsubstitution:1.100,context:1.400\n",
      "Pseudo count b                         \tsubstitution:4.100,context:5.800\n",
      "Score bias                             \t0\n",
      "Realign hits                           \tfalse\n",
      "Realign score bias                     \t-0.2\n",
      "Realign max seqs                       \t2147483647\n",
      "Correlation score weight               \t0\n",
      "Gap open cost                          \taa:11,nucl:5\n",
      "Gap extension cost                     \taa:1,nucl:2\n",
      "Zdrop                                  \t40\n",
      "Threads                                \t48\n",
      "Compressed                             \t0\n",
      "Verbosity                              \t3\n",
      "Seed substitution matrix               \taa:VTML80.out,nucl:nucleotide.out\n",
      "Sensitivity                            \t5.7\n",
      "k-mer length                           \t0\n",
      "Target search mode                     \t0\n",
      "k-score                                \tseq:2147483647,prof:2147483647\n",
      "Alphabet size                          \taa:21,nucl:5\n",
      "Max results per query                  \t1\n",
      "Split database                         \t0\n",
      "Split mode                             \t2\n",
      "Split memory limit                     \t0\n",
      "Diagonal scoring                       \ttrue\n",
      "Exact k-mer matching                   \t0\n",
      "Mask residues                          \t1\n",
      "Mask residues probability              \t0.9\n",
      "Mask lower case residues               \t0\n",
      "Minimum diagonal score                 \t15\n",
      "Selected taxa                          \t\n",
      "Spaced k-mers                          \t1\n",
      "Spaced k-mer pattern                   \t\n",
      "Local temporary path                   \t\n",
      "Rescore mode                           \t0\n",
      "Remove hits by seq. id. and coverage   \tfalse\n",
      "Sort results                           \t0\n",
      "Mask profile                           \t1\n",
      "Profile E-value threshold              \t0.001\n",
      "Global sequence weighting              \tfalse\n",
      "Allow deletions                        \tfalse\n",
      "Filter MSA                             \t1\n",
      "Use filter only at N seqs              \t0\n",
      "Maximum seq. id. threshold             \t0.9\n",
      "Minimum seq. id.                       \t0.0\n",
      "Minimum score per column               \t-20\n",
      "Minimum coverage                       \t0\n",
      "Select N most diverse seqs             \t1000\n",
      "Pseudo count mode                      \t0\n",
      "Min codons in orf                      \t30\n",
      "Max codons in length                   \t32734\n",
      "Max orf gaps                           \t2147483647\n",
      "Contig start mode                      \t2\n",
      "Contig end mode                        \t2\n",
      "Orf start mode                         \t1\n",
      "Forward frames                         \t1,2,3\n",
      "Reverse frames                         \t1,2,3\n",
      "Translation table                      \t1\n",
      "Translate orf                          \t0\n",
      "Use all table starts                   \tfalse\n",
      "Offset of numeric ids                  \t0\n",
      "Create lookup                          \t0\n",
      "Add orf stop                           \tfalse\n",
      "Overlap between sequences              \t0\n",
      "Sequence split mode                    \t1\n",
      "Header split mode                      \t0\n",
      "Chain overlapping alignments           \t0\n",
      "Merge query                            \t1\n",
      "Search type                            \t3\n",
      "Search iterations                      \t1\n",
      "Start sensitivity                      \t4\n",
      "Search steps                           \t1\n",
      "Prefilter mode                         \t0\n",
      "Exhaustive search mode                 \tfalse\n",
      "Filter results during exhaustive search\t0\n",
      "Strand selection                       \t1\n",
      "LCA search mode                        \tfalse\n",
      "Disk space limit                       \t0\n",
      "MPI runner                             \t\n",
      "Force restart with latest tmp          \tfalse\n",
      "Remove temporary files                 \ttrue\n",
      "Alignment format                       \t0\n",
      "Format alignment output                \tquery,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits\n",
      "Database output                        \tfalse\n",
      "Overlap threshold                      \t0\n",
      "Database type                          \t0\n",
      "Shuffle input database                 \ttrue\n",
      "Createdb mode                          \t0\n",
      "Write lookup file                      \t0\n",
      "Greedy best hits                       \tfalse\n",
      "\n",
      "createdb gene-taxa-dataset/taxa_out.fasta tmp/1850168531918110490/query --dbtype 0 --shuffle 1 --createdb-mode 0 --write-lookup 0 --id-offset 0 --compressed 0 -v 3 \n",
      "\n",
      "Converting sequences\n",
      "[11717] 0s 194ms\n",
      "Time for merging to query_h: 0h 0m 0s 162ms\n",
      "Time for merging to query: 0h 0m 0s 228ms\n",
      "Database type: Nucleotide\n",
      "Time for processing: 0h 0m 0s 848ms\n",
      "createdb gene-taxa-dataset/train.fasta tmp/1850168531918110490/target --dbtype 0 --shuffle 1 --createdb-mode 0 --write-lookup 0 --id-offset 0 --compressed 0 -v 3 \n",
      "\n",
      "Converting sequences\n",
      "[547522] 1s 23mss\n",
      "Time for merging to target_h: 0h 0m 0s 334ms\n",
      "Time for merging to target: 0h 0m 1s 885ms\n",
      "Database type: Nucleotide\n",
      "Time for processing: 0h 0m 5s 601ms\n",
      "Create directory tmp/1850168531918110490/search_tmp\n",
      "search tmp/1850168531918110490/query tmp/1850168531918110490/target tmp/1850168531918110490/result tmp/1850168531918110490/search_tmp --alignment-mode 3 --max-accept 1 -s 5.7 --max-seqs 1 --search-type 3 --remove-tmp-files 1 \n",
      "\n",
      "splitsequence tmp/1850168531918110490/target tmp/1850168531918110490/search_tmp/7517960967491305636/target_seqs_split --max-seq-len 10000 --sequence-overlap 0 --sequence-split-mode 1 --headers-split-mode 0 --create-lookup 0 --threads 48 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 547.52K 0s 159ms                        ] 22.69% 124.26K eta 0s             ] 58.13% 318.27K eta 0s       \n",
      "Time for merging to target_seqs_split_h: 0h 0m 0s 492ms\n",
      "Time for merging to target_seqs_split: 0h 0m 0s 423ms\n",
      "Time for processing: 0h 0m 1s 881ms\n",
      "extractframes tmp/1850168531918110490/query tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs --forward-frames 1 --reverse-frames 1 --create-lookup 0 --threads 48 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 11.80K 0s 40ms     \n",
      "Time for merging to query_seqs_h: 0h 0m 0s 238ms\n",
      "Time for merging to query_seqs: 0h 0m 0s 393ms\n",
      "Time for processing: 0h 0m 1s 355ms\n",
      "splitsequence tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs_split --max-seq-len 10000 --sequence-overlap 0 --sequence-split-mode 1 --headers-split-mode 0 --create-lookup 0 --threads 48 --compressed 0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 13ms\n",
      "prefilter tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs_split tmp/1850168531918110490/search_tmp/7517960967491305636/target_seqs_split tmp/1850168531918110490/search_tmp/7517960967491305636/search/pref_0 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --seed-sub-mat 'aa:VTML80.out,nucl:nucleotide.out' -k 15 --target-search-mode 0 --k-score seq:2147483647,prof:2147483647 --alph-size aa:21,nucl:5 --max-seq-len 10000 --max-seqs 1 --split 0 --split-mode 2 --split-memory-limit 0 -c 0 --cov-mode 0 --comp-bias-corr 1 --comp-bias-corr-scale 1 --diag-score 1 --exact-kmer-matching 1 --mask 1 --mask-prob 0.9 --mask-lower-case 0 --min-ungapped-score 15 --add-self-matches 0 --spaced-kmer-mode 1 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --threads 48 --compressed 0 -v 3 -s 5.7 \n",
      "\n",
      "Query database size: 23600 type: Nucleotide\n",
      "Estimated memory consumption: 13G\n",
      "Target database size: 547524 type: Nucleotide\n",
      "Index table k-mer threshold: 0 at k-mer size 15 \n",
      "Index table: counting k-mers\n",
      "[=================================================================] 100.00% 547.52K 3s 692ms    \n",
      "Index table: Masked residues: 1623736\n",
      "Index table: fill\n",
      "[=================================================================] 100.00% 547.52K 4s 551ms    \n",
      "Index statistics\n",
      "Entries:          565048906\n",
      "DB size:          11425 MB\n",
      "Avg k-mer size:   0.526243\n",
      "Top 10 k-mers\n",
      "    CACTGACCCGAACAC\t1590\n",
      "    CAGTTACTCCCACGA\t1218\n",
      "    CACTGACTCCGCAGC\t1137\n",
      "    AAGAATGACAGGCGC\t1038\n",
      "    CACTGACTCATGAGT\t902\n",
      "    CAGTGACGCGTCTGT\t847\n",
      "    TACTAAGACATACGG\t826\n",
      "    TACGCCGCGTATTCG\t636\n",
      "    GAAGATGCGTACGGG\t617\n",
      "    TTCTGAGAGTTGGGT\t528\n",
      "Time for index table init: 0h 0m 15s 40ms\n",
      "Process prefiltering step 1 of 1\n",
      "\n",
      "k-mer similarity threshold: 0\n",
      "Starting prefiltering scores calculation (step 1 of 1)\n",
      "Query db start 1 to 23600\n",
      "Target db start 1 to 547524\n",
      "[=================================================================] 100.00% 23.60K 0s 435ms    \n",
      "\n",
      "0.967888 k-mers per position\n",
      "2575 DB matches per sequence\n",
      "0 overflows\n",
      "0 sequences passed prefiltering per query sequence\n",
      "1 median result list length\n",
      "1553 sequences with 0 size result lists\n",
      "Time for merging to pref_0: 0h 0m 0s 164ms\n",
      "Time for processing: 0h 0m 16s 38ms\n",
      "align tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs_split tmp/1850168531918110490/search_tmp/7517960967491305636/target_seqs_split tmp/1850168531918110490/search_tmp/7517960967491305636/search/pref_0 tmp/1850168531918110490/search_tmp/7517960967491305636/aln --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' -a 0 --alignment-mode 3 --alignment-output-mode 0 --wrapped-scoring 0 -e 0.001 --min-seq-id 0 --min-aln-len 0 --seq-id-mode 0 --alt-ali 0 -c 0 --cov-mode 0 --max-seq-len 10000 --comp-bias-corr 1 --comp-bias-corr-scale 1 --max-rejected 2147483647 --max-accept 1 --add-self-matches 0 --db-load-mode 0 --pca substitution:1.100,context:1.400 --pcb substitution:4.100,context:5.800 --score-bias 0 --realign 0 --realign-score-bias -0.2 --realign-max-seqs 2147483647 --corr-score-weight 0 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --zdrop 40 --threads 48 --compressed 0 -v 3 \n",
      "\n",
      "Compute score, coverage and sequence identity\n",
      "Query database size: 23600 type: Nucleotide\n",
      "Target database size: 547524 type: Nucleotide\n",
      "Calculation of alignments\n",
      "[=================================================================] 100.00% 23.60K 0s 106ms    \n",
      "Time for merging to aln: 0h 0m 0s 162ms\n",
      "22047 alignments calculated\n",
      "10253 sequence pairs passed the thresholds (0.465052 of overall calculated)\n",
      "0.434449 hits per query sequence\n",
      "Time for processing: 0h 0m 0s 636ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/search/pref_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 80ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/search/aln_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/search/input_0 -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/search/aln_merge -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "offsetalignment tmp/1850168531918110490/query tmp/1850168531918110490/search_tmp/7517960967491305636/query_seqs_split tmp/1850168531918110490/target tmp/1850168531918110490/search_tmp/7517960967491305636/target_seqs_split tmp/1850168531918110490/search_tmp/7517960967491305636/aln tmp/1850168531918110490/result --chain-alignments 0 --merge-query 1 --search-type 3 --threads 48 --compressed 0 --db-load-mode 0 -v 3 \n",
      "\n",
      "Computing ORF lookup\n",
      "Computing contig offsets\n",
      "Computing contig lookup\n",
      "Time for contig lookup: 0h 0m 0s 39ms\n",
      "Writing results to: tmp/1850168531918110490/result\n",
      "[=================================================================] 100.00% 11.80K 0s 36ms                               ] 11.76% 1.39K eta 0s       \n",
      "\n",
      "Time for merging to result: 0h 0m 0s 152ms\n",
      "Time for processing: 0h 0m 0s 575ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/q_orfs -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/q_orfs_aa -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/t_orfs -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 1ms\n",
      "rmdb tmp/1850168531918110490/search_tmp/7517960967491305636/t_orfs_aa -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 0ms\n",
      "convertalis tmp/1850168531918110490/query tmp/1850168531918110490/target tmp/1850168531918110490/result ./taxa_out.m8 --sub-mat 'aa:blosum62.out,nucl:nucleotide.out' --format-mode 0 --format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits --translation-table 1 --gap-open aa:11,nucl:5 --gap-extend aa:1,nucl:2 --db-output 0 --db-load-mode 0 --search-type 3 --threads 48 --compressed 0 -v 3 \n",
      "\n",
      "[=================================================================] 100.00% 11.80K 0s 46ms                         ] 64.84% 7.65K eta 0s       \n",
      "Time for merging to taxa_out.m8: 0h 0m 0s 270ms\n",
      "Time for processing: 0h 0m 0s 648ms\n",
      "rmdb tmp/1850168531918110490/result -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 99ms\n",
      "rmdb tmp/1850168531918110490/target -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 38ms\n",
      "rmdb tmp/1850168531918110490/target_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 12ms\n",
      "rmdb tmp/1850168531918110490/query -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 8ms\n",
      "rmdb tmp/1850168531918110490/query_h -v 3 \n",
      "\n",
      "Time for processing: 0h 0m 0s 3ms\n"
     ]
    }
   ],
   "source": [
    "!mmseqs easy-search gene-taxa-dataset/taxa_out.fasta gene-taxa-dataset/train.fasta ./taxa_out.m8 tmp --max-accept 1  --max-seqs 1 --search-type 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f548d7-1895-4f3f-b1a3-c91507dc0586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981ea48b-9c19-40ff-8262-ca1346ac38be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## BERTax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217e093-44ed-4cc0-9fac-6d3e3e878421",
   "metadata": {},
   "source": [
    "### Download BERTax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be93a53-32af-4486-81af-a7867700e89b",
   "metadata": {},
   "source": [
    "We have **Singularity** available, but you could alternatively use the Docker file provided by DeepMicrobes to set up the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcd861-c846-495d-96ab-066600aa881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!singularity pull --tmpdir $(pwd) $(pwd)/bertax.sif docker://fkre/bertax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a59d869-8d59-4a87-b3f5-5db10341b7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63961442-e10c-44f7-93cc-20a513c2f540",
   "metadata": {},
   "source": [
    "### Run Bertax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2a6f20-d92b-4b8a-af55-e3dc74fbb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!singularity run --bind ${PWD}:/mnt  --nv bertax.sif  -o /mnt/gene-taxa-dataset/result_test.txt   /mnt/gene-taxa-dataset/test.fasta  --batch_size 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef8e44-8281-49c6-bc2a-9ad505e59186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7299ef32-fb20-4ee8-bec5-90c38ecc9c92",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DeepMicrobes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64bf7cc-6cbe-4116-873c-d517ceda703e",
   "metadata": {},
   "source": [
    "#### Running DeepMicrobes: Guidelines\n",
    "\n",
    "Please follow the detailed DeepMicrobes documentation for running their model and formatting processes. We explicitly follow their documentation for the two key steps:\n",
    "\n",
    "1. **Create TFRecord**  \n",
    "   Follow the instructions in the DeepMicrobes documentation to generate TFRecord files:  \n",
    "   [Create TFRecord Documentation](https://github.com/MicrobeLab/DeepMicrobes/blob/master/document/tfrecord.md)\n",
    "\n",
    "2. **Train DeepMicrobes**  \n",
    "   Refer to the DeepMicrobes training documentation to train the model:  \n",
    "   [Train DeepMicrobes Documentation](https://github.com/MicrobeLab/DeepMicrobes/blob/master/document/train.md)\n",
    "\n",
    "---\n",
    "###### Adaptation in Our Work\n",
    "We also included the two core parameters from DeepMicrobes to train our own DeepMicrobes-based model on the gene-taxa dataset.  \n",
    "We trained two different DeepMicrobes models: one for family and the other for gene, to ensure a fair comparison on the same dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4af866-6ebc-441f-8a73-8f6750ae52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tfrec_train_kmer.sh -i train_gene_label.fasta -v ./DeepMicrobes/tokens_merged_8mers.txt -o train_gene.tfrec -k 8 -s 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5f55b-aa7e-442d-82a1-05661d03d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -u DeepMicrobes.py \\\n",
    "  --input_tfrec train_gene.tfrec \\\n",
    "  --model_name attention \\\n",
    "  --model_dir gene_model \\\n",
    "  --num_classes 437 \\\n",
    "  --vocab_size 32898 \\\n",
    "  --train_epochs 20 \\\n",
    "  --batch_size 256 \\\n",
    "  --max_len 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157af785-0233-4266-8127-328b6bcf5ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9e69d-3487-4fb5-aebb-6ab60d32db39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867102e7-e26b-486b-8979-a26dd2004af0",
   "metadata": {},
   "source": [
    "# ART Simulation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32177da1-1960-4e40-b8ae-583fbe24d1bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Install Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02abaf2-fae6-453f-a438-36d7c242d825",
   "metadata": {},
   "source": [
    "We suggest running the following command in the terminal instead of in a notebook!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5bf0962-c2ec-46c2-81ea-e8a781a2af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-09 18:57:22--  https://www.niehs.nih.gov/sites/default/files/2024-02/artsrcmountrainier2016.06.05linux.tgz\n",
      "Resolving www.niehs.nih.gov (www.niehs.nih.gov)... 104.18.14.200, 104.18.15.200, 2606:4700::6812:fc8, ...\n",
      "Connecting to www.niehs.nih.gov (www.niehs.nih.gov)|104.18.14.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12242989 (12M) [application/x-gzip]\n",
      "Saving to: ‘artsrcmountrainier2016.06.05linux.tgz’\n",
      "\n",
      "artsrcmountrainier2 100%[===================>]  11.68M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-11-09 18:57:22 (86.7 MB/s) - ‘artsrcmountrainier2016.06.05linux.tgz’ saved [12242989/12242989]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.niehs.nih.gov/sites/default/files/2024-02/artsrcmountrainier2016.06.05linux.tgz\n",
    "!tar -xvzf artsrcmountrainier2016.06.05linux.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9362a2-6343-4400-abe2-a7b7dc51ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd art_src_MountRainier_Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99e4ba6-a024-4bd7-a5d8-8deb938e69b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!./configure \n",
    "!make\n",
    "!make install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9932ffd-95d0-4b82-b091-e298f23a55c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63bd3383-6e1b-4bd2-a1ee-902f1e2e7cae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generate ART Simulated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a66b97-2321-4c43-bff4-3b24f3096945",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./art_src_MountRainier_Linux/art_illumina -ss HS25 -i ./gene-taxa-dataset/gene_out.fasta -l 150 -f 20 -m 200 -s 10 -o simulated_art\n",
    "\n",
    "!awk 'NR % 4 == 1 {print \">\" substr($0, 2)} NR % 4 == 2 {print}' simulated_art.fq> gene_out_art.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ef9adb-5115-4792-bf62-cfe975a40f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4bd8d-1f71-474d-b2ca-26b4564458b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77727de-b0f9-4b57-9074-158b2c7d5949",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###  Kraken2 Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb08f4-2fd6-4e95-a970-cf200a65f8fd",
   "metadata": {},
   "source": [
    "##### We just used the database created in the previous section of Kraken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55dc377f-23fb-4790-a81b-6c5729425278",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ART_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd948e48-1483-43fe-a5bd-0245ccc11da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad43db82-2e18-48c1-afac-cb1445cb9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO:   \u001b[0m User not listed in /etc/subuid, trying root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m Using fakeroot command combined with root-mapped namespace\n",
      "\u001b[34mINFO:   \u001b[0m underlay of /etc/localtime required more than 50 (79) bind mounts\n",
      "Loading database information... done.\n",
      "2969056 sequences (445.36 Mbp) processed in 20.621s (8638.8 Kseq/m, 1295.82 Mbp/m).\n",
      "  11258 sequences classified (0.38%)\n",
      "  2957798 sequences unclassified (99.62%)\n"
     ]
    }
   ],
   "source": [
    "!singularity exec --fakeroot --bind {os.getcwd()}:/data kraken2_latest.sif \\\n",
    "    kraken2 --db /data/data-gene/databases \\\n",
    "    --output /data/ART_output/kraken2_results.txt \\\n",
    "    --report /data/ART_output/kraken2_report.txt \\\n",
    "    --minimum-hit-groups 1 \\\n",
    "    --confidence 0 \\\n",
    "    /data/gene_out_art.fasta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c114410e-ee9a-4e42-a2b4-3e6895380b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f43fe-f4d3-4262-b8f1-7657b622a678",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a9323d7-efe5-4cf6-8072-5fcea9ab0f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def traverse_nodes(initial_taxid, nodes_dict):\n",
    "    taxids = [initial_taxid]\n",
    "    ranks = []\n",
    "    wanted_ranks = np.array(['superkingdom','kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species'])\n",
    "    \n",
    "    while initial_taxid in nodes_dict.keys():\n",
    "        taxid, rank = nodes_dict[initial_taxid]\n",
    "        taxids.append(taxid)\n",
    "        ranks.append(rank)\n",
    "        initial_taxid = taxid\n",
    "        if initial_taxid == 1:\n",
    "            break\n",
    "    ranks = np.array(ranks)\n",
    "    mask = np.nonzero(np.in1d(ranks, wanted_ranks))[0]\n",
    "        \n",
    "    taxids = list(np.array(taxids)[mask])\n",
    "    ranks = list(np.array(ranks)[mask])\n",
    "    zipped_taxids = dict(zip(ranks, taxids))\n",
    "\n",
    "    return zipped_taxids\n",
    "\n",
    "#tree file\n",
    "nodes = pd.read_csv('./data-gene/databases/taxonomy/nodes.dmp', delimiter = \"\\t\", header=None, skipinitialspace=True, usecols=[0,2,4])\n",
    "nodes.rename(columns={0: 'taxid', 2: 'prev_taxid', 4: 'rank'}, inplace=True)\n",
    "\n",
    "#taxid -> name file\n",
    "names = pd.read_csv('./data-gene/databases/taxonomy/names.dmp', delimiter = \"\\t\", header=None, skipinitialspace=True, usecols=[0,2])\n",
    "names.rename(columns={0: 'taxid', 2: 'name'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eb5f23-c260-474c-a2e2-6bbbcbf19dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e39740-a0e4-448c-9671-9db76217f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "#List of taxids\n",
    "basic = pd.read_csv('./ART_output/kraken2_results.txt', delimiter = \"\\t\", header=None, skipinitialspace=True) # usecols=[0,2])\n",
    "\n",
    "basic[\"orginal_index\"] = basic[1].str.extract(r'seqid\\|(\\d+)', expand=False).astype(int)\n",
    "basic[\"taxid\"] = basic[1].str.extract(r'taxid\\|(\\d+)', expand=False).astype(int)\n",
    "\n",
    "basic.rename(columns={2: 'pred_taxid'}, inplace=True)\n",
    "\n",
    "#traverse tree\n",
    "values = list(zip(nodes['prev_taxid'], nodes['rank']))\n",
    "keys = list(nodes['taxid'])\n",
    "nodes_dict = dict(map(lambda i,j : (i,j) , keys,values))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db48eabf-02e4-4139-8b6f-fb6c72f106ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e2e4242-8ba4-430d-ae41-7ac6a7b59009",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_taxa = basic.copy()\n",
    "full_taxa['real_taxa'] = full_taxa.apply(lambda row: traverse_nodes(row['taxid'], nodes_dict), axis=1)\n",
    "                                                  \n",
    "lineage = pd.DataFrame(list(full_taxa['real_taxa'])).fillna(0).astype('Int64') # lineage from taxid  \n",
    "\n",
    "full_taxa = basic.copy()\n",
    "full_taxa['real_taxa'] = full_taxa.apply(lambda row: traverse_nodes(row['pred_taxid'], nodes_dict), axis=1)\n",
    "lineage_pred = pd.DataFrame(list(full_taxa['real_taxa'])).fillna(0).astype('Int64') # lineage from taxid   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cff5e6-bfd1-4e7b-9bd3-158c8606536e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede618c7-d5a0-478c-88ed-8d30b972bc6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07709bfe-c873-4d7e-9928-8a6a32d445ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialize accuracy dictionary to store accuracy for each level\n",
    "accuracy = {}\n",
    "\n",
    "# Loop through each level\n",
    "for level in lineage.columns:\n",
    "    # Check if the level exists in both DataFrames\n",
    "    if level in lineage_pred.columns:\n",
    "        # Count the number of matching values at this level, while ignoring rows where lineage_pred value is zero\n",
    "        matches = ((lineage[level] == lineage_pred[level]) & (lineage_pred[level] != 0)).sum()\n",
    "        # Count the total number of non-zero values in lineage_pred at this level\n",
    "        total_values = len(lineage)\n",
    "        # Calculate accuracy\n",
    "        if total_values != 0:\n",
    "            level_accuracy = matches / total_values\n",
    "        else:\n",
    "            level_accuracy = None\n",
    "        # Store accuracy for this level\n",
    "        accuracy[level] = level_accuracy\n",
    "\n",
    "# Print accuracy for each level\n",
    "for level, acc in accuracy.items():\n",
    "    print(f\"Accuracy for level {level}: {acc * 100}\") \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf274ee9-9929-41a7-9828-c4272bd8e4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90b67b-21a1-44f7-bf34-a415307a2667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18db0dd-cf44-44c6-9ab3-40324abeb36c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ec1ccc0-d9cd-4a68-82a5-16ac591bcf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "for level in lineage.columns:\n",
    "    # Filter out zero predictions\n",
    "    ground_truth = lineage[level][lineage_pred[level] != 0]\n",
    "    predictions = lineage_pred[level][lineage_pred[level] != 0]\n",
    "    \n",
    "    # Calculate the confusion matrix\n",
    "    cm = confusion_matrix(ground_truth, predictions)\n",
    "\n",
    "    \n",
    "    # Calculate F1-score with macro averaging\n",
    "    level_f1_score = f1_score(ground_truth, predictions, average='macro', zero_division=0)\n",
    "    print(f\"F1-Score for {level}: {level_f1_score * 100}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9a821-4cc8-4b25-99df-c5a6268dee03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69324223-2d09-45ab-adfe-2aa5faf42de6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0ea0d-17c3-406d-8e9b-e92beffab5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d76c0a-f20b-4597-a96d-1c9a35789e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
